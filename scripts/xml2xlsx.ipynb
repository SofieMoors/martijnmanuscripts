{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da42733f-7d67-4841-a1b6-6815b8889c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (0.21.1)\n",
      "Requirement already satisfied: Levenshtein==0.21.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from python-Levenshtein) (0.21.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from Levenshtein==0.21.1->python-Levenshtein) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a553b4f-3038-47f5-8c54-7d41dc978869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grapheme in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: pandas in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: seaborn in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.40.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scipy in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (from scipy) (1.26.1)\n",
      "Requirement already satisfied: numpy in /Users/sofiemoors/miniconda3/lib/python3.10/site-packages (1.26.1)\n",
      "Collecting numpy\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/76/ac/dea2939dfc3c591a2494121669455fd7d049248ef284c9542904ddbe05d5/numpy-1.26.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading numpy-1.26.2-cp310-cp310-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.2-cp310-cp310-macosx_10_9_x86_64.whl (20.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.1\n",
      "    Uninstalling numpy-1.26.1:\n",
      "      Successfully uninstalled numpy-1.26.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "papie 0.4.2 requires typing, which is not installed.\n",
      "papie 0.4.2 requires numpy<1.24.0,>=1.14.3, but you have numpy 1.26.2 which is incompatible.\n",
      "pie-extended 0.1.2 requires numpy<1.24.0, but you have numpy 1.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.2\n"
     ]
    }
   ],
   "source": [
    "!pip install grapheme\n",
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "!pip install scipy\n",
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "structured-peripheral",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os \n",
    "from itertools import combinations \n",
    "import grapheme \n",
    "from collatex import * \n",
    "from tqdm import tqdm \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sb \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from lxml import etree\n",
    "from re import sub \n",
    "import xml.etree.ElementTree as ET\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "passing-morgan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A',\n",
       " 'Ant',\n",
       " 'B',\n",
       " 'Br',\n",
       " 'C',\n",
       " 'D',\n",
       " 'D2',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'Ge',\n",
       " 'K',\n",
       " 'L',\n",
       " 'O',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigles = [os.path.basename(fn).replace('xml_', '').replace('.xml', '') for fn in glob('../data/xml/*.xml')] \n",
    "sigles = sorted(sigles)\n",
    "sigles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defensive-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigles = 'A','Ant','B', 'Br', 'C','D', 'D2','E', 'F', 'G', 'Ge', 'K', 'L', 'O', 'W', 'Y', 'Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e3f5b1-9208-465a-9b4c-da840fca53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gap_lines(tree):\n",
    "    gap_lines = []\n",
    "    for text in tree.iterfind('.//' + \"{\" + NSMAP[\"MVN\"] + \"}\" + 'text'):\n",
    "        if 'n' in text.attrib:\n",
    "            for line in text.iterfind('.//' + \"{\" + NSMAP[\"MVN\"] + \"}\" + 'l'):\n",
    "                if line.find('.//' + \"{\" + NSMAP[\"MVN\"] + \"}\" + 'gap') is not None:\n",
    "                    if 'n' in line.attrib:\n",
    "                        n_value = line.attrib['n']\n",
    "                        parts = n_value.split('_')\n",
    "                        if len(parts) > 1:\n",
    "                            k = \"_\".join(parts[1:])  # Join the parts after the first underscore\n",
    "                        else:\n",
    "                            k = n_value\n",
    "                        gap_lines.append(k)\n",
    "\n",
    "    return gap_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d7932ef-cb69-49d8-ac57-f98adf065ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSMAP = {'MVN': 'http://www.tei-c.org/ns/1.0'} \n",
    "removes = ('teiHeader', 'fw', 'supplied', 'abbr')\n",
    "removes_expan_false = ('teiHeader', 'fw', 'supplied', 'ex', 'expan')\n",
    "chars = {'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l','m', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'}       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threaded-camera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "{'M1_47_606': '', 'M1_47_607': '', 'M1_47_608': 'ijt', 'M1_47_609': '', 'M1_47_610': '', 'M1_47_611': '', 'M1_48_612': '', 'M1_48_613': '', 'M1_48_614': '', 'M1_48_615': '', 'M1_48_616': 'jn', 'M1_48_617': '', 'M1_48_618': '', 'M1_48_619': '', 'M1_48_620': '', 'M1_48_621': '', 'M1_48_622': '', 'M1_48_623': '', 'M1_48_624': '', 'M1_49_625': '', 'M1_49_626': 't', 'M1_49_627': '', 'M1_49_628': '', 'M1_49_629': '', 'M1_49_630': '', 'M1_49_631': '', 'M1_49_632': '', 'M1_49_633': '', 'M1_49_634': '', 'M1_49_635': '', 'M1_49_636': '', 'M1_49_637': '', 'M1_50_638': '', 'M1_50_639': '', 'M1_50_640': '', 'M1_50_641': '', 'M1_50_642': '', 'M1_50_643': '', 'M1_50_644': 'soe viel ', 'M1_50_645': 'dus moch', 'M1_50_646': 'en*de€ clare', 'M1_50_647': 'miltheit h', 'M1_50_648': 'vrecheit l', 'M1_50_649': 'dit proeu', 'M1_50_650': 'die winn', 'M1_51_651': 'iacob e', 'M1_51_652': 'als d', 'M1_51_653': 'van gher', 'M1_51_654': 'doet d*er€ og', 'M1_51_655': 'oft comt', 'M1_51_656': 'dit euel t', 'M1_51_657': 'ic liet m', 'M1_51_658': 'en*de€ ics vr', 'M1_51_659': 'maect mi ', 'M1_51_660': 'mijn hert', 'M1_51_661': 'mine besce', 'M1_51_662': 'en es niet', 'M1_51_663': 'na dat ic', 'M1_52_664': 'merte*n€ du ', 'M1_52_665': 'du spr', 'M1_52_666': 'die noch n', 'M1_52_667': 'alrehand', 'M1_52_668': 'comt van', 'M1_52_669': 'd*at€ noit do', 'M1_52_670': 'hem en m', 'M1_52_671': 'die stille ', 'M1_52_672': '', 'M1_52_673': '', 'M1_52_674': '', 'M1_52_675': '', 'M1_52_676': '', 'M1_53_677': '', 'M1_53_678': '', 'M1_53_679': '', 'M1_53_680': '', 'M1_53_681': '', 'M1_53_682': 'en', 'M1_53_683': 'n wijt', 'M1_53_684': 'r di lijt', 'M1_53_685': 'ts geloge*n€', 'M1_53_686': 'neg*er€ tijt', 'M1_53_687': 'vor lijt', 'M1_53_688': 'gen', 'M1_53_689': 'n', 'M1_54_690': 'elijc viant', 'M1_54_691': 'menege*n€ pant', 'M1_54_692': '', 'M1_54_693': 'ere di vant', 'M1_54_694': 'uus en*de€ lant', 'M1_54_695': ' houde', 'M1_54_696': 'en bant', 'M1_54_697': 'n .i. sant', 'M1_54_698': 'ude', 'M1_54_699': 'metterha*n€t', 'M1_54_700': 'lke*n€ pant', 'M1_54_701': 'moude', 'M1_54_702': 'woude', 'M1_55_703': 'ge sprac', 'M1_55_704': 'ins gebrac', 'M1_55_705': 'nne', 'M1_55_706': 'ongemac', 'M1_55_707': 'uwert lac', 'M1_55_708': 'emt mi i*n€ne', 'M1_55_709': 'le wt stac'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def extract_lines(xml_file, expan = True,  \n",
    "                  punct = True, lower = True,\n",
    "                  sep_abbr = True): \n",
    "    lines = {}\n",
    "    tree = etree.parse(xml_file) \n",
    "    \n",
    "    if expan:\n",
    "        etree.strip_elements(tree, (\"{\"+ NSMAP[\"MVN\"]+ \"}\" + s for s in removes), with_tail=False) \n",
    "    else: \n",
    "        etree.strip_elements(tree, (\"{\"+ NSMAP[\"MVN\"]+ \"}\" + s for s in removes_expan_false), with_tail=False)\n",
    "  \n",
    "    context = etree.iterwalk(tree, events=(\"start\", \"end\"))\n",
    "    text = u\"\" \n",
    "    k = '' \n",
    "    \n",
    "    for action, node in context: \n",
    "        tag_only = node.tag.replace(\"{http://www.tei-c.org/ns/1.0}\",\"\")  #remove ns for easier access\n",
    "        if 'n' in node.attrib and tag_only == 'text': \n",
    "            title = node.attrib['n'] \n",
    "\n",
    "        if 'n' in node.attrib and tag_only == \"l\":\n",
    "           # k = node.attrib['n']\n",
    "            n_value = node.attrib['n']\n",
    "            parts = n_value.split('_')\n",
    "            if len(parts) > 1:\n",
    "                k = \"_\".join(parts[1:])  \n",
    "            else:\n",
    "                k = n_value \n",
    "        # if a new pb (standalone element) is processed:\n",
    "        if action == 'start' and tag_only == 'text': \n",
    "            continue\n",
    "            \n",
    "        elif action == 'start' and tag_only == 'lg':\n",
    "            continue \n",
    "            \n",
    "        # if new lb (standalone) is processed:\n",
    "        elif action == 'start' and tag_only == 'lb':\n",
    "            continue\n",
    "\n",
    "        # list elements which you want to iterate through. this is not really neccessary.\n",
    "        elif tag_only in (\"group\",\"text\",\"MVN\",\"body\",\"cb\",\"p\",\"note\"):\n",
    "            continue\n",
    "\n",
    "        # for all other elements, distinguish bet ween the start-event of the processing and\n",
    "        # and the end-event. Attach the tail AFTER the child nodes were processed (= end-event) \n",
    "         \n",
    "        elif action == 'start':\n",
    "            #comment the following two lines out to not get the element markers\n",
    "            #f.write(f\"[{tag_only}]\") \n",
    "            #text += f\"[{tag_only}]\"\n",
    "\n",
    "            ############################################################################\n",
    "            ########## filter out special characters, bars,                   ##########\n",
    "            ########## superscript, or specific tags.                         ##########\n",
    "            ############################################################################\n",
    "                    \n",
    "            \n",
    "            #if a special glyph is present, encode it accordingly\n",
    "                \n",
    "            if tag_only == 'g':\n",
    "                if sep_abbr:\n",
    "                    if node.attrib['ref'] == '#bar': # ā, ē, ī, ō, ū, n̄ etc.\n",
    "                        text += u'\\u005f' #low line _\n",
    "\n",
    "                    elif node.attrib['ref'] == '#apomod': # ʼ\n",
    "                        text += u'\\u02bc'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#usmod': # ꝰ\n",
    "                        text += u'\\ua770' \n",
    "\n",
    "                    elif node.attrib['ref'] == '#condes': # ꝯ\n",
    "                        text += u'\\ua76f'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#para': # ¶\n",
    "                        text += u'\\xb6'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#etfin': # ꝫ\n",
    "                        text += u'\\ua76b'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝑ\n",
    "                        text += '\\ua751'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝕ\n",
    "                        text += u'\\ua755'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pflour': # ꝓ\n",
    "                        text += u'\\ua753'\n",
    "                        \n",
    "                    elif node.attrib['ref'] == '#rrot': #ꝛ\n",
    "                        text += (u'\\uA75B')\n",
    "                    else:\n",
    "                        text += str(node.attrib['ref']) # get the actual ref if there still are any left\n",
    "                    \n",
    "                else:\n",
    "                    if node.attrib['ref'] == '#bar': # ā, ē, ī, ō, ū, n̄ etc.\n",
    "                        text += u'\\u0304'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#apomod': # ʼ\n",
    "                        text += u'\\u02bc'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#usmod': # ꝰ\n",
    "                        text += u'\\ua770'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#condes': # ꝯ\n",
    "                        text += u'\\ua76f'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#para': # ¶\n",
    "                        text += u'\\xb6'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#etfin': # ꝫ\n",
    "                        text += u'\\ua76b'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝑ\n",
    "                        text += u'\\ua751'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pbardes': # ꝕ\n",
    "                        text += u'\\ua755'\n",
    "\n",
    "                    elif node.attrib['ref'] == '#pflour': # ꝓ\n",
    "                        text += u'\\ua753'\n",
    "                        \n",
    "                    elif node.attrib['ref'] == '#rrot': #ꝛ\n",
    "                        text += (u'\\uA75B')\n",
    "\n",
    "                    else:\n",
    "                        node.attrib['ref']\n",
    "                        text += str(node.attrib['ref']) # get the actual ref if there still are any left\n",
    "\n",
    "            # encode superscript letters\n",
    "            superscript_dict = {'a':'ᵃ', 'b':'ᵇ', 'c':'ᶜ', 'd':'ᵈ', 'e':'ᵉ', 'f':'ᶠ',\n",
    "                               'g':'ᵍ', 'h':'ʰ', 'i':'ᶦ', 'j':'ʲ', 'k':'ᵏ', 'l':'ˡ', \n",
    "                                'm':'ᵐ', 'n':'ⁿ', 'o':'ᵒ', 'p':'ᵖ', 'r':'ʳ', 's':'ˢ', \n",
    "                                't':'ᵗ', 'u':'ᵘ', 'v':'ᵛ', 'w':'ʷ', 'x':'ˣ', 'y': 'ʸ', 'z': 'ᶻ'}\n",
    "\n",
    "            if tag_only == 'hi' and 'rend' in node.attrib and node.attrib['rend'] == 'superscript': #rend(ition) supplies information about the appearance of an element\n",
    "                if node.text in superscript_dict:\n",
    "                    text += str(superscript_dict[node.text]).strip()\n",
    "\n",
    "            elif tag_only == 'ex':\n",
    "                    text += str('*'+node.text+'€')\n",
    "\n",
    "            # encode punctuation marks\n",
    "            elif tag_only == 'pc':\n",
    "                text += str(node.text).strip()\n",
    "\n",
    "            # encode roman numerals\n",
    "            elif tag_only == 'num':\n",
    "                if node.text:\n",
    "                    text += str('.'+node.text+'.').strip()\n",
    "\n",
    "            # if there is still a node with text in it\n",
    "            elif (node.text):\n",
    "                text += node.text        \n",
    "\n",
    "        # after the child elements\n",
    "        elif action == 'end':\n",
    "            #if there is a tail\n",
    "            if (node.tail and node.tail not in \"\\t\"): #if the tail is not yet in the text \n",
    "                #comment the following two lines out to not get the tail marker\n",
    "                #text += \"[tail]\"\n",
    "                #f.write(\"[tail]\")\n",
    "                #append to text-concatenation\n",
    "                text += str(node.tail)\n",
    "\n",
    "        if tag_only == 'l' or tag_only == 'lg':\n",
    "            if k: \n",
    "                text = sub(r'\\n', '', text) \n",
    "                \n",
    "        if tag_only == 'lb':\n",
    "            if k:\n",
    "                text = sub(r'\\n', '', text)\n",
    "                if not punct:\n",
    "                    punctuation_with_pilcrow = string.punctuation + '¶' + '⸫'\n",
    "                    text = text.translate(str.maketrans('', '', punctuation_with_pilcrow))\n",
    "                    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "                if lower: \n",
    "                    text = text.lower()\n",
    "                   \n",
    "                    #text = text[::-1]\n",
    "                  \n",
    "                lines[k] = text \n",
    "\n",
    "                text = ''   \n",
    "    # catch dangling last line (if applicable):\n",
    "    if text:\n",
    "        lines[k] = text\n",
    "    text = sub(r'\\n', '', text)  # Verwijder nieuwe regels\n",
    "\n",
    "    if not punct:\n",
    "        punctuation_with_pilcrow = string.punctuation + '¶' + '⸫'\n",
    "        text = text.translate(str.maketrans('', '', punctuation_with_pilcrow))\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        #text = text.translate(str.maketrans('', '', string.punctuation))  # Verwijder interpunctie\n",
    "    if lower:\n",
    "        text = text.lower()  # Zet om naar kleine letters\n",
    "    lines[k] = text \n",
    "    num_orig_lines = len(lines)\n",
    "    print(num_orig_lines)\n",
    "    # remove lines with gaps:\n",
    "    #gap_lines = get_gap_lines(tree)\n",
    "    #lines = {k:v for k, v in lines.items() if k not in gap_lines}\n",
    "    #print(f'-> removed {num_orig_lines - len(lines)} lines with gaps')\n",
    "    #lines = {k:v for k, v in lines.items() if v.strip()} #if a line with a gap is removed, remove empty key, strip() removes spaces #The items() method returns a key-value pair\n",
    "    \n",
    "    return lines\n",
    "    #num_orig_lines = len(lines)\n",
    "    #print(num_orig_lines)\n",
    "d = extract_lines(f'../data/xml/xml_{sigles[1]}.xml', expan = True, punct = True, lower = True)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "iraqi-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████████████████████████████████████████████████████▉                                                              | 9/17 [00:00<00:00, 42.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1767\n",
      "104\n",
      "1816\n",
      "604\n",
      "1472\n",
      "1811\n",
      "247\n",
      "276\n",
      "1821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [00:00<00:00, 42.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "148\n",
      "67\n",
      "700\n",
      "1821\n",
      "508\n",
      "348\n",
      "534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mss = {} \n",
    "for sigle in tqdm(sigles): \n",
    "    mss[sigle] = extract_lines(f'../data/xml/xml_{sigle}.xml',\n",
    "                               expan = True, punct = True, lower = True,\n",
    "                               sep_abbr = False) \n",
    "#print(mss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d8eab91-da70-4fbe-a8f1-65cc42d3c892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A', 'Ant', 'B', 'Br', 'C', 'D', 'D2', 'E', 'F', 'G', 'Ge', 'K', 'L', 'O', 'W', 'Y', 'Z'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "653067b2-54e0-4aac-9e93-f5103c8fea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "idx = set()\n",
    "for ms in mss:\n",
    "    idx.update(set(mss[ms].keys()))\n",
    "idx = sorted(idx)\n",
    "witnesses = sorted(mss.keys())\n",
    "\n",
    "lines = np.empty([len(idx), len(witnesses)], dtype=\"object\")\n",
    "\n",
    "for ms in mss.keys():\n",
    "    for l in mss[ms]:\n",
    "        lines[idx.index(l), witnesses.index(ms)] = mss[ms][l].replace('*', '<i>').replace('€', '</i>')\n",
    "\n",
    "lines = pd.DataFrame(lines, index=idx, columns=witnesses)\n",
    "lines.to_html('../data/xlsx/synoptic.html', escape=False) #import this html in Excel to get xlsx with exapansions in cursive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12d0a0-9c42-4a4f-a0b5-39eb76bd9848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
