{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this script to convert rich txt files (i.e. txt with markup annotation) to the MVN xml-standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from copy import deepcopy\n",
    "\n",
    "def add_numbers(text_file):\n",
    "    output = []\n",
    "    \n",
    "    with open(text_file, 'r', encoding='utf-8') as input_file: \n",
    "        input = input_file.readlines() \n",
    "\n",
    "    last_line = 0\n",
    "    for index, line in enumerate(input): \n",
    "        if not re.match(r'^§', line) and not re.match(r'^§', line) and not re.match(r'^&', line) and not re.match(r'^_', line) and not re.match(r'\\s*\\n', line): \n",
    "            # igore lines with & or _ \n",
    "            if re.match(r'^[0-9]', line):\n",
    "                try:\n",
    "                    last_line = int(re.sub(' .*$', '', line)) \n",
    "                    line_number = str(last_line).zfill(3)\n",
    "                    line_no_number = (re.sub('^[0-9]* ', '', line)).strip()\n",
    "                    if line_no_number:\n",
    "                        output.append([line_number, line_no_number])\n",
    "                except: \n",
    "                    last_line += 1\n",
    "            if not re.match(r'^[0-9]', line): \n",
    "                last_line += 1 \n",
    "                line_number = str(last_line).zfill(3)\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    output.append([line_number, line])  \n",
    "        else:\n",
    "            output.append(['no_content_line', line.strip()])\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "import glob, os\n",
    "\n",
    "rubric = re.compile(r\"(\\<)([a-zA-Z]+)(\\>)\")\n",
    "boundaries = re.compile(r\"(\\[|\\]|\\(|\\)|\\%|\\$|\\=|\\{|\\}|\\*|\\£|\\@)\")\n",
    "endings = re.compile(r\"(\\)|\\]|\\%|\\$|\\=|\\}|\\*|\\£|@)$\")\n",
    "beginnings = re.compile(r\"$\\(|\\[|\\{\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/rich_txt/txt_Ant.txt\n",
      "../data/rich_txt/txt_C.txt\n",
      "../data/rich_txt/txt_B.txt\n",
      "../data/rich_txt/txt_W.txt\n",
      "../data/rich_txt/txt_A.txt\n",
      "../data/rich_txt/txt_E.txt\n",
      "../data/rich_txt/txt_D.txt\n",
      "../data/rich_txt/txt_Ge.txt\n",
      "../data/rich_txt/txt_F.txt\n",
      "../data/rich_txt/txt_G.txt\n",
      "../data/rich_txt/txt_Br.txt\n",
      "../data/rich_txt/txt_K.txt\n",
      "../data/rich_txt/txt_D2.txt\n",
      "../data/rich_txt/txt_L.txt\n",
      "../data/rich_txt/txt_Z.txt\n",
      "../data/rich_txt/txt_O.txt\n",
      "../data/rich_txt/txt_Y.txt\n",
      "../data/rich_txt/headers_footer/headerAnt.txt\n",
      "../data/rich_txt/headers_footer/headerD2.txt\n",
      "../data/rich_txt/headers_footer/headerD.txt\n",
      "../data/rich_txt/headers_footer/headerE.txt\n",
      "../data/rich_txt/headers_footer/headerG.txt\n",
      "../data/rich_txt/headers_footer/headerBr.txt\n",
      "../data/rich_txt/headers_footer/headerF.txt\n",
      "../data/rich_txt/headers_footer/headerB.txt\n",
      "../data/rich_txt/headers_footer/headerC.txt\n",
      "../data/rich_txt/headers_footer/headerA.txt\n",
      "../data/rich_txt/headers_footer/headerW.txt\n",
      "../data/rich_txt/headers_footer/headerZ.txt\n",
      "../data/rich_txt/headers_footer/headerL.txt\n",
      "../data/rich_txt/headers_footer/headerY.txt\n",
      "../data/rich_txt/headers_footer/headerO.txt\n",
      "../data/rich_txt/headers_footer/headerK.txt\n",
      "../data/rich_txt/headers_footer/header.txt\n",
      "../data/rich_txt/headers_footer/footer.txt\n",
      "../data/rich_txt/headers_footer/headerGe.txt\n"
     ]
    }
   ],
   "source": [
    "# path to the rich txt files\n",
    "txt_path = '../data/rich_txt/'\n",
    "file_paths = []\n",
    "\n",
    "for root, dirs, files in os.walk(txt_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\"checkpoint.txt\"): # disregard txt files that are Notebook Checkpoints\n",
    "            continue\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_paths.append(file_path)\n",
    "            print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def abbr_to_xml(kind, solution):\n",
    "    abbr, expan = \"\", \"\"\n",
    "\n",
    "    if kind == \"$\":\n",
    "        if \"_\" in solution:\n",
    "            val, nr = solution.split(\"_\")\n",
    "            abbr = '<hi rend=\"capitalsize'+nr+'\">'+val+'</hi>'\n",
    "        else:\n",
    "            abbr = '<hi rend=\"capitalsize1\">'+solution+'</hi>'\n",
    "        expan = abbr\n",
    "    elif kind == \"@\":\n",
    "        abbr = \"<del>\"+solution+\"</del>\"\n",
    "        expan = abbr\n",
    "    elif kind == \"=\":\n",
    "        abbr = '<num type=\"roman\">'+solution+'</num>'\n",
    "        expan = abbr\n",
    "    elif kind == \"£\":\n",
    "        abbr = '<g ref=\"#slongbar\"/>'\n",
    "        expan = \"<ex>\"+solution+\"</ex>\"\n",
    "    elif kind == \"*\":\n",
    "        abbr = '<unclear>'+solution+'</unclear>'\n",
    "        expan = abbr\n",
    "    elif kind == \"(\":\n",
    "        abbr = '<g ref=\"#bar\"/>'\n",
    "        expan = \"<ex>\"+solution+\"</ex>\"\n",
    "    elif kind == \"[\":\n",
    "        if solution == \"ist\":\n",
    "            abbr = 'p<g ref=\"#bar\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        else:\n",
    "            abbr = '<g ref=\"#apomod\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "    elif kind == \"{\":\n",
    "        if solution == \"et\" or solution == \"iet\" or solution == \"at\":\n",
    "            abbr = '<g ref=\"#etfin\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"pro\":\n",
    "            abbr = '<g ref=\"#pflour\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"par\" or solution == \"paer\":\n",
    "            abbr = '<g ref=\"#pbardes\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"per\":\n",
    "            abbr = '<g ref=\"#pbardes\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"con\" or solution == \"com\":\n",
    "            abbr = '<g ref=\"#condes\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"us\" or solution == 'as': # careful, -as abbreviated as ꝰ (-us) is very rare!\n",
    "            abbr = '<g ref=\"#usmod\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"eit\" or solution == 'ijt': # careful, -ijt abbreviated as 'etfin' is very rare!\n",
    "            abbr = '<g ref=\"#etfin\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "    elif kind == \"%\":\n",
    "        if solution == \"rv\":\n",
    "            abbr = '<hi rend=\"superscript\">v</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"ri\":\n",
    "            abbr = '<hi rend=\"superscript\">i</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"ur\" or solution == \"er\":\n",
    "            #abbr = '<hi rend=\"superscript\">z</hi>'\n",
    "            abbr = '<hi rend=\"superscript\"><g ref=\"#rrot\"/></hi>'\n",
    "            #abbr = '<g ref=\"#rrot\"/>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"ue\":\n",
    "            abbr = '<hi rend=\"superscript\">e</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"ro\":\n",
    "            abbr = '<hi rend=\"superscript\">o</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"roe\" or solution == 'rou':\n",
    "            abbr = '<hi rend=\"superscript\">o</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"ua\":\n",
    "            abbr = '<hi rend=\"superscript\">a</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"ra\" or solution == \"aer\": # careful, -aer/-ai abbreviated as superscript a is very rare!\n",
    "            abbr = '<hi rend=\"superscript\">a</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"re\":\n",
    "            abbr = '<hi rend=\"superscript\">e</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        elif solution == \"eit\" or solution == \"iet\":\n",
    "            abbr = '<hi rend=\"superscript\">t</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "        else:\n",
    "            abbr = '<hi rend=\"superscript\">'+solution+'</hi>'\n",
    "            expan = \"<ex>\"+solution+\"</ex>\"\n",
    "    return abbr, expan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_abbrevs(word):\n",
    "    # insert dummy boundary marker:\n",
    "    w = boundaries.sub(r\"|\\1\", word)\n",
    "    if not \"|\" in w:\n",
    "        return word\n",
    "    abbr = \"\"\n",
    "    expan = \"\"\n",
    "    prev_kind = \"\"\n",
    "    for part in w.split(\"|\"):\n",
    "        part = endings.sub(\"\", part).strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        if (part[0] == \"%\" and prev_kind == \"%\") or \\\n",
    "            (part[0] == \"$\" and prev_kind == \"$\") or \\\n",
    "            (part[0] == \"=\" and prev_kind == \"=\") or \\\n",
    "            (part[0] == \"*\" and prev_kind == \"*\") or \\\n",
    "            (part[0] == \"£\" and prev_kind == \"£\") or \\\n",
    "            (part[0] == \"@\" and prev_kind == \"@\") or \\\n",
    "            (part[0] in \")]}\"):\n",
    "            part = part[1:]\n",
    "        if part:\n",
    "            if part[0] in \"({[%$=*£@\":\n",
    "                kind = part[0]\n",
    "                prev_kind = kind\n",
    "                solution = part[1:]\n",
    "                a, e = abbr_to_xml(kind, solution)\n",
    "                abbr += a\n",
    "                expan += e\n",
    "            else:\n",
    "                abbr += part\n",
    "                expan += part\n",
    "    if abbr != expan:\n",
    "        abbr = \"<abbr>\"+abbr+\"</abbr>\"\n",
    "        expan = \"<expan>\"+expan+\"</expan>\"\n",
    "        return '<choice>'+abbr+expan+'</choice>'\n",
    "    else:\n",
    "        return abbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def convert_to_xml(file_path):\n",
    "    \n",
    "    file_name = os.path.basename(file_path)\n",
    "    variant_name = file_name.split('.')[0].split('_')[1]\n",
    "    print(\"Parsing...\")\n",
    "    print(\"\\t\", \"Variant:\", variant_name)\n",
    "    \n",
    "    martijns = {'_M1_': 'Eerste Martijn', '_M2_': 'Tweede Martijn', '_M3_': 'Derde Martijn', '_Colofon_': 'Colofon'}\n",
    "    \n",
    "    #MAUD \n",
    "    lines = add_numbers(file_path)\n",
    "    \n",
    "    xml = \"\"\n",
    "        \n",
    "    for item in lines:\n",
    "        line_number = item[0]\n",
    "        line = item[1]\n",
    "        stanza_counter = 0 \n",
    "        line = line.replace(\">\", \"$\").replace(\"<\", \"$\")\n",
    "        \n",
    "        # gaps that are the result of damage are marked as [...] in the txt file; replace with € (which later gets replaced with the appropriate tag)\n",
    "        line = line.replace(\"[...]\", \"€\")\n",
    "        #print(line)\n",
    "        \n",
    "        # txt files have to start with a &-marker, indicating the folium\n",
    "        if line.startswith(\"&\"):\n",
    "            curr_page_nr = line.replace(\"&\", \"\")\n",
    "            xml += '\\n\\n<pb xml:id=\"' + variant_name + '.f' + curr_page_nr + '\" n=\"' + curr_page_nr + '\"/>\\n'\n",
    "            line_counter = 0\n",
    "            \n",
    "        # within a page, a specific text (e.g. Eerste Martijn) can start; these are marked with an underscore (e.g. _M1_)\n",
    "        # these texts are assigned to unique tags (e.g. <text n=\"1\" xml:id=\"M1\"> ... </text>, <text n=\"2\" xml:id=\"M2\"> ... </text> )\n",
    "\n",
    "            \n",
    "        elif line.startswith(\"_\"):\n",
    "            for key, value in martijns.items():\n",
    "                if line == key:\n",
    "                    mart_xml_id = key.replace(\"_\", \"\")\n",
    "                    xml += '\\n\\n<text n=\"' + str(value) + '\" xml:id=\"' + mart_xml_id + '\">\\n<body>\\n<p>'\n",
    "    \n",
    "            if line == \"____\": # 4 underscores in a txt-file mark the end of a text-element\n",
    "                xml += f'</lg>\\n</p>\\n</body>\\n</text>\\n'\n",
    "\n",
    "                \n",
    "        elif line.startswith(\"§\"):\n",
    "            curr_stanza = line.replace(\"§\", \"\")\n",
    "            if re.match(r'^\\d', curr_stanza):# Check if curr_stanza starts with a digit\n",
    "                if curr_stanza:\n",
    "                    if not xml.endswith('<p>'):  # Check if the previous tag is not <p>\n",
    "                        xml += '</lg>\\n'  # Close the previous <lg> tag if it exists and the previous tag is not <p>\n",
    "                xml += '<lg type=\"stanza\" n=\"' + str(curr_stanza) + '\">\\n'\n",
    "           \n",
    "        #MAUD\n",
    "        elif line_number != 'no_content_line':\n",
    "            if line == 'Ø':\n",
    "                xml += f'\\n<note n=\"{variant_name}_{mart_xml_id}_{curr_stanza}_{line_number}\">Line_number {line_number} is missing</note>\\n'\n",
    "            else:\n",
    "                line_counter += 1\n",
    "                trailer = \"\"\n",
    "                if line.endswith(\"#\"):\n",
    "                    trailer += '<choice><sic></sic><corr><c type=\"shy\">-</c></corr></choice>'\n",
    "                    line = line[:-1]\n",
    "                words = line.split()\n",
    "                \n",
    "                # MAUD \n",
    "                l_with_number = f'\"/><l n=\"{variant_name}_{mart_xml_id}_{curr_stanza}_{line_number}\">' if line_number != 'no_content_line' else '\"/><l>'\n",
    "                \n",
    "                xml += '<lb n=\"' + str(line_counter) + '\" xml:id=\"' + variant_name + 'f' + str(curr_page_nr) + '.' + str(line_counter) + l_with_number\n",
    "                \n",
    "                for i, word in enumerate(words):\n",
    "                    if word in string.punctuation:\n",
    "                        xml += '<pc>' + word + '</pc> '\n",
    "                    else:\n",
    "                        xml += parse_abbrevs(word) + \" \"\n",
    "                xml = xml.strip()\n",
    "                xml = xml.replace(\"C|\", '<g ref=\"#para\"/>')\n",
    "                xml += trailer\n",
    "                xml += \"</l>\"\n",
    "                xml += \"\\n\"\n",
    "                xml = xml.replace(\"€\", '<damage><gap></gap></damage>')\n",
    "                #xml = xml.replace(\" € \", ' <damage><gap extent=\"totally_lost\"></gap></damage> ')\n",
    "                #xml = xml.replace(\" €\", ' <damage><gap extent=\"partially_lost\"></gap></damage> ')\n",
    "                #xml = xml.replace(\"€ \", ' <damage><gap extent=\"partially_lost\"></gap></damage> ')\n",
    "\n",
    "    header_file = \"../data/rich_txt/headers_footer/header\"+variant_name+\".txt\"\n",
    "    with open(header_file, 'r') as file:\n",
    "        header = file.read()\n",
    "    footer = open(\"../data/rich_txt/headers_footer/footer.txt\", 'r').read()\n",
    "    with open(\"../data/xml/xml_\"+variant_name+\".xml\", \"w+\", errors=\"replace\", encoding='utf-8') as F:\n",
    "        F.write(header + xml + footer)\n",
    "\n",
    "# Example usage\n",
    "#convert_to_xml(\"input_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing...\n",
      "\t Variant: Ant\n",
      "Parsing...\n",
      "\t Variant: C\n",
      "Parsing...\n",
      "\t Variant: B\n",
      "Parsing...\n",
      "\t Variant: W\n",
      "Parsing...\n",
      "\t Variant: A\n",
      "Parsing...\n",
      "\t Variant: E\n",
      "Parsing...\n",
      "\t Variant: D\n",
      "Parsing...\n",
      "\t Variant: Ge\n",
      "Parsing...\n",
      "\t Variant: F\n",
      "Parsing...\n",
      "\t Variant: G\n",
      "Parsing...\n",
      "\t Variant: Br\n",
      "Parsing...\n",
      "\t Variant: K\n",
      "Parsing...\n",
      "\t Variant: D2\n",
      "Parsing...\n",
      "\t Variant: L\n",
      "Parsing...\n",
      "\t Variant: Z\n",
      "Parsing...\n",
      "\t Variant: O\n",
      "Parsing...\n",
      "\t Variant: Y\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_path \u001b[38;5;129;01min\u001b[39;00m file_paths:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mconvert_to_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[44], line 7\u001b[0m, in \u001b[0;36mconvert_to_xml\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_xml\u001b[39m(file_path):\n\u001b[1;32m      6\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\n\u001b[0;32m----> 7\u001b[0m     variant_name \u001b[38;5;241m=\u001b[39m \u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariant:\u001b[39m\u001b[38;5;124m\"\u001b[39m, variant_name)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for file_path in file_paths:\n",
    "    convert_to_xml(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
